2.1. Чи можна на основі даних зробити висновок про успішність тесту?

    Ні, на даному етапі не можна. Хоча ми бачимо номінальний ріст Conversion Rate, різниця може бути статистично не значущою.

    Я провів перевірку (Z-test/Chi-Square) і отримав такі результати:

    1. Різниця конверсій: +0.25% (відносний ріст +10%)

    2. P-value ≈ 0.26 (це значно більше за стандартний поріг 0.05).

    Висновок: Результат не є статистично значущим. Ми не можемо відхилити нульову гіпотезу. З імовірністю 26% така різниця виникла випадково. Впроваджувати зміни ризиковано.

2.2. Яких даних вам не вистачає для повноцінного аналізу?

    Для повноцінного аналізу мені не вистачає контексту:

    Тривалість тесту: Чи тривав тест достатньо довго (наприклад, 2 повні бізнес-цикли), щоб уникнути впливу днів тижня?

    Сегментація користувачів: Чи рівномірно розподілилися користувачі за платформами (iOS/Android) та джерелами трафіку? Можливо, в тестову групу випадково потрапило більше лояльних юзерів.

    Вартість залучення: Чи змінилася структура трафіку під час тесту?

    Сезонність та Події: Чи не було зовнішніх подій (свята, розпродажі) під час тесту?

2.3. Які метрики, окрім конверсії, варто було б відстежувати?

    Окрім Conversion Rate, критично важливо дивитися на:

    AOV: Конверсія могла вирости, бо ми знизили ціни або пропонували дешеві товари, але загальний дохід міг впасти.

    ARPU / Revenue per User: Фінальна метрика грошей. Вона показує, чи реально група B принесла більше прибутку.

    Retention Rate: Чи не випалила нова кнопка базу користувачів? Чи повернуться вони знову?

    Технічні метрики: Час завантаження сторінки. Можливо, нова кнопка гальмує сайт.